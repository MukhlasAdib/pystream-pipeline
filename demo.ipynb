{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Dict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "from pystream import Pipeline, Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycle period for the input data\n",
    "INPUT_PERIOD = 0.2\n",
    "# Time to run the pipeline\n",
    "ON_TIME = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyStage(Stage):\n",
    "    \"\"\"A dummy stage that performs some convolutions to the input 2D array,\n",
    "    and count how many input it has processed.\n",
    "    \n",
    "    It is recommended to define 'name' property in the stage instance init\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name: str) -> None:\n",
    "        \"\"\"Initialize stage\n",
    "\n",
    "        Args:\n",
    "            name (str): stage name\n",
    "        \"\"\"        \n",
    "        self.count = 0\n",
    "        self.name = name\n",
    "        self.kernel = np.random.randint(-10, 10, size=(5, 5))\n",
    "\n",
    "    def __call__(self, data: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Main data processing of the stage, a mandatory method of the Stage \n",
    "        class. Note that the stage does not return a new dict object, but only\n",
    "        modifies the input object and returns it as the output\n",
    "\n",
    "        Args:\n",
    "            data (Dict[str, np.ndarray]): the input array, packed\n",
    "                in a dictionary\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, np.ndarray]: the output array, packed\n",
    "            in a dictionary\n",
    "        \"\"\"\n",
    "        img = data[\"data\"]\n",
    "        for _ in range(100):\n",
    "            img = cv2.filter2D(src=img, ddepth=-1, kernel=self.kernel)\n",
    "        data[\"data\"] = img\n",
    "        self.count += 1\n",
    "        return data\n",
    "\n",
    "    def cleanup(self):\n",
    "        \"\"\"Cleanup method, called at the end of the pipeline.\n",
    "        in this example, we want to reset the counter to 0\"\"\"\n",
    "        self.count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data() -> Dict[str, np.ndarray]:\n",
    "    img = np.random.randint(0, 255, size=(480, 720, 3), dtype=np.uint8)\n",
    "    return {\"data\": img}\n",
    "\n",
    "def create_pipeline() -> Pipeline:\n",
    "    # First, create the pipeline instance, we want to use the profiler\n",
    "    pipeline = Pipeline(input_generator=generate_data, use_profiler=True)\n",
    "    # Now, add 5 dummy stages to the pipeline.\n",
    "    pipeline.add(DummyStage(\"Stage1\"))\n",
    "    pipeline.add(DummyStage(\"Stage2\"))\n",
    "    pipeline.add(DummyStage(\"Stage3\"))\n",
    "    pipeline.add(DummyStage(\"Stage4\"))\n",
    "    pipeline.add(DummyStage(\"Stage5\"))\n",
    "    return pipeline\n",
    "\n",
    "def print_profile(latency: Dict[str, float], throughput: Dict[str, float]):\n",
    "    data = []\n",
    "    for k in latency.keys():\n",
    "        d = [k, latency[k], throughput[k]]\n",
    "        data.append(d)\n",
    "    table = tabulate(data, headers=[\"Stage\", \"Latency (s)\", \"Throughput (d/s)\"])\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline in serial...\n",
      "Waiting for 5 s...\n",
      "Stopping pipeline...\n",
      "\n",
      "Last output shape:\n",
      "(480, 720, 3)\n",
      "\n",
      "Pipeline profile:\n",
      "Stage       Latency    Throughput\n",
      "--------  ---------  ------------\n",
      "Stage1     0.173414       1.1411\n",
      "Stage2     0.165654       1.1476\n",
      "Stage3     0.180477       1.15147\n",
      "Stage4     0.160584       1.14935\n",
      "Stage5     0.162539       1.14617\n",
      "Pipeline   0.842698       1.14617\n"
     ]
    }
   ],
   "source": [
    "pipeline = create_pipeline()\n",
    "print(\"Starting pipeline in serial...\")\n",
    "pipeline.serialize()\n",
    "print(f\"Streaming data each {INPUT_PERIOD} s...\")\n",
    "pipeline.start_loop(INPUT_PERIOD)\n",
    "print(f\"Waiting for {ON_TIME} s...\")\n",
    "time.sleep(ON_TIME)\n",
    "print(\"Stopping pipeline...\")\n",
    "pipeline.stop_loop()\n",
    "\n",
    "# Let's try read the last result and do cleanup\n",
    "latest = pipeline.get_results()\n",
    "print()\n",
    "print(\"Last output shape:\")\n",
    "print(latest[\"data\"].shape)\n",
    "pipeline.cleanup()\n",
    "\n",
    "# Get the profile\n",
    "latency, throughput = pipeline.get_profiles()\n",
    "print()\n",
    "print(\"Pipeline profile:\")\n",
    "print_profile(latency, throughput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[PyStream] 2023-03-30 20:40:19,247 - INFO      : (Stage1 9496) Thread started...\n",
      "[PyStream] 2023-03-30 20:40:19,365 - INFO      : (Stage2 15652) Thread started...\n",
      "[PyStream] 2023-03-30 20:40:19,368 - INFO      : (Stage3 10060) Thread started...\n",
      "[PyStream] 2023-03-30 20:40:19,368 - INFO      : (Stage4 16652) Thread started...\n",
      "[PyStream] 2023-03-30 20:40:19,372 - INFO      : (Stage5 18200) Thread started...\n",
      "[PyStream] 2023-03-30 20:40:19,372 - INFO      : (FinalStage 11460) Thread started...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline in parallel...\n",
      "Streaming data each 0.2 s...\n",
      "Waiting for 5 s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[PyStream] 2023-03-30 20:40:24,432 - INFO      : (Stage5 18200) Terminating thread...\n",
      "[PyStream] 2023-03-30 20:40:24,443 - INFO      : (FinalStage 11460) Terminating thread...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping pipeline...\n",
      "\n",
      "Last output shape:\n",
      "(480, 720, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[PyStream] 2023-03-30 20:40:24,620 - INFO      : (Stage3 10060) Terminating thread...\n",
      "[PyStream] 2023-03-30 20:40:24,626 - INFO      : (Stage4 16652) Terminating thread...\n",
      "[PyStream] 2023-03-30 20:40:24,638 - INFO      : (Stage2 15652) Terminating thread...\n",
      "[PyStream] 2023-03-30 20:40:24,639 - INFO      : (Stage1 9496) Terminating thread...\n",
      "[PyStream] 2023-03-30 20:40:25,446 - INFO      : (Stage5 18200) Thread terminated...\n",
      "[PyStream] 2023-03-30 20:40:25,446 - INFO      : (FinalStage 11460) Thread terminated...\n",
      "[PyStream] 2023-03-30 20:40:25,632 - INFO      : (Stage4 16652) Thread terminated...\n",
      "[PyStream] 2023-03-30 20:40:25,632 - INFO      : (Stage3 10060) Thread terminated...\n",
      "[PyStream] 2023-03-30 20:40:25,648 - INFO      : (Stage1 9496) Thread terminated...\n",
      "[PyStream] 2023-03-30 20:40:25,648 - INFO      : (Stage2 15652) Thread terminated...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pipeline profile:\n",
      "Stage       Latency    Throughput\n",
      "--------  ---------  ------------\n",
      "Stage1     0.229076       4.34578\n",
      "Stage2     0.220657       4.29952\n",
      "Stage3     0.222065       4.2608\n",
      "Stage4     0.233113       4.24435\n",
      "Stage5     0.235186       4.21391\n",
      "Pipeline   1.32022        4.21369\n"
     ]
    }
   ],
   "source": [
    "pipeline = create_pipeline()\n",
    "print(\"Starting pipeline in parallel...\")\n",
    "pipeline.parallelize()\n",
    "print(f\"Streaming data each {INPUT_PERIOD} s...\")\n",
    "pipeline.start_loop(INPUT_PERIOD)\n",
    "print(f\"Waiting for {ON_TIME} s...\")\n",
    "time.sleep(ON_TIME)\n",
    "print(\"Stopping pipeline...\")\n",
    "pipeline.stop_loop()\n",
    "\n",
    "# Let's try read the last result and do cleanup\n",
    "latest = pipeline.get_results()\n",
    "print()\n",
    "print(\"Last output shape:\")\n",
    "print(latest[\"data\"].shape)\n",
    "pipeline.cleanup()\n",
    "\n",
    "# Get the profile\n",
    "latency, throughput = pipeline.get_profiles()\n",
    "print()\n",
    "print(\"Pipeline profile:\")\n",
    "print_profile(latency, throughput)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystream-pipeline-b0R0VbC--py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
